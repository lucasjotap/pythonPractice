{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import basedosdados as bd\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "          .builder \\\n",
    "          .config(\"spark.sql.caseSensitive\", \"true\") \\\n",
    "          .config(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\") \\\n",
    "          .config(\"spark.sql.sources.commitProtocolClass\",\"org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol\") \\\n",
    "          .appName(\"ipca_etl\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATASET = \"br_ibge_ipca\"\n",
    "SOURCE_TABLE = \"mes_brasil\"\n",
    "GCP_PROJECT_ID = \"puc-gcp-sources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_table = bd.read_table(\n",
    "    dataset_id=SOURCE_DATASET,\n",
    "    table_id=SOURCE_TABLE,\n",
    "    billing_project_id=GCP_PROJECT_ID\n",
    ")\n",
    "df = spark.createDataFrame(raw_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createTempView(\"stg_ipca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_current_year = '''\n",
    "  SELECT *\n",
    "  FROM stg_ipca\n",
    "  WHERE ano = 2022\n",
    "  ORDER BY mes;\n",
    "'''\n",
    "\n",
    "df_ipca_2022 = spark.sql(query_current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ipca_2022.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_month_inflation_rates_query = '''\n",
    "    SELECT\n",
    "        CONCAT(ano, \"-\", mes) AS mes,\n",
    "        variacao_mensal\n",
    "    FROM stg_ipca\n",
    "    WHERE variacao_mensal <> 'NaN'\n",
    "    ORDER BY variacao_mensal DESC\n",
    "    LIMIT 10;\n",
    "'''\n",
    "spark.sql(highest_month_inflation_rates_query) \\\n",
    "      .toPandas() \\\n",
    "      .plot \\\n",
    "      .bar(x=\"mes\", y=\"variacao_mensal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anual_variation_historic = '''\n",
    "    SELECT\n",
    "      ano,\n",
    "      variacao_anual\n",
    "    FROM stg_ipca\n",
    "    WHERE mes = 12\n",
    "        AND ano BETWEEN 2000 AND 2011\n",
    "    ORDER BY ano DESC;\n",
    "'''\n",
    "spark.sql(anual_variation_historic) \\\n",
    "      .toPandas() \\\n",
    "      .plot \\\n",
    "      .line(x=\"ano\", y=\"variacao_anual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1) \\\n",
    "  .write \\\n",
    "  .format(\"csv\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save(\"ibge_ipca_brasil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_inflation = '''\n",
    "  SELECT \n",
    "      CONCAT(ano, \"-\", mes) AS mes,\n",
    "      variacao_mensal\n",
    "    FROM stg_ipca\n",
    "    WHERE variacao_mensal <> 'NaN'\n",
    "    ORDER BY variacao_mensal ASC\n",
    "    LIMIT 10;\n",
    "'''\n",
    "\n",
    "df_ipca_low_inflation = spark.sql(lowest_inflation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ipca_low_inflation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_inflation = '''\n",
    "    SELECT\n",
    "        CONCAT(ano, \"-\", mes) AS mes,\n",
    "        variacao_mensal\n",
    "    FROM stg_ipca\n",
    "    WHERE variacao_mensal <> 'NaN'\n",
    "    ORDER BY variacao_mensal DESC\n",
    "    LIMIT 10;\n",
    "'''\n",
    "# spark.sql(high_inflation) \\\n",
    "  #    .toPandas() \\\n",
    "   #   .plot \\\n",
    "    #  .bar(x=\"mes\", y=\"variacao_mensal\")\n",
    "\n",
    "hi_inflation = spark.sql(high_inflation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_inflation.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
